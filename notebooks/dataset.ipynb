{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/y-chiba1008/talk-support-asr/blob/main/notebooks/dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -q \"datasets[audio]\""
      ],
      "metadata": {
        "id": "5hcbljTLpVTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r6ZmchS6PXci"
      },
      "outputs": [],
      "source": [
        "# ドライブのdataフォルダをマウント\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "## Google Driveをマウント\n",
        "drive.mount('/drive')\n",
        "\n",
        "## シンボリックリンクの作成\n",
        "### drive_folder_path: ドライブ内の目的のフォルダのパス\n",
        "drive_folder_path = '/drive/Othercomputers/マイ コンピュータ/data'\n",
        "\n",
        "### colab_link_path: Colab内の短縮されたアクセスパス\n",
        "colab_link_path = '/content/data'\n",
        "\n",
        "### リンク先が既に存在する場合は削除\n",
        "if os.path.isdir(colab_link_path):\n",
        "    print(f'{colab_link_path}がすでに存在する為、一度削除します')\n",
        "    !rm -rf \"$colab_link_path\"\n",
        "\n",
        "### シンボリックリンクを作成\n",
        "!ln -s \"$drive_folder_path\" \"$colab_link_path\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1DMdWGNZTOA1"
      },
      "outputs": [],
      "source": [
        "# 定数\n",
        "# data_name = '01_short'\n",
        "# data_name = '02_all'\n",
        "# data_name = '03_data_augment'\n",
        "data_name = '04_all_and_normal'\n",
        "APPLY_AUGMENT = False\n",
        "ADD_NORMAL = True\n",
        "\n",
        "WAV_DIR = 'data/wav'\n",
        "JSON_PATH = f'data/{data_name}/label_studio.json'\n",
        "JSON_PATH_NORMAL = f'data/{data_name}/label_studio_normal.json'\n",
        "AUDIOFOLDER_PATH = f'data/{data_name}/audiofolder'\n",
        "PREPROCESSED_DATA_PATH = f'data/{data_name}/preprocessed_data'\n",
        "BASE_MODEL = 'openai/whisper-small'\n",
        "NUM_PROC = 4\n",
        "SEED = 42"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## audiofolder作成"
      ],
      "metadata": {
        "id": "fFzM-rBncqgB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "def reshape_data(json_data: list[dict]) -> pd.DataFrame:\n",
        "    '''下記の形に整形する\n",
        "      - wav_path\n",
        "      - start\n",
        "      - end\n",
        "      - sentence\n",
        "    '''\n",
        "\n",
        "    label_datas = []\n",
        "    for task in json_data:\n",
        "        wav_dir_path = Path(WAV_DIR)\n",
        "        orgfile_path = Path(task['data']['audio'])\n",
        "        file_path = wav_dir_path / orgfile_path.name\n",
        "\n",
        "        results = []\n",
        "        for ano in task['annotations']:\n",
        "            results += ano['result']\n",
        "        results = filter(lambda res: res['type'] == 'textarea', results)\n",
        "\n",
        "        wav_path = str(file_path)\n",
        "        wav_path = wav_path.replace('?d=wav%5C', '')\n",
        "\n",
        "        for res in results:\n",
        "            label_datas.append({\n",
        "                'wav_path': wav_path,\n",
        "                'start': res['value']['start'],\n",
        "                'end': res['value']['end'],\n",
        "                'sentence': res['value']['text'][0]\n",
        "            })\n",
        "\n",
        "    df_label_datas = pd.DataFrame(label_datas)\n",
        "    return df_label_datas"
      ],
      "metadata": {
        "id": "mYTPjXcsQetf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_save_path(df_data_list: pd.DataFrame,\n",
        "                  split_dir_names: list[str],\n",
        "                  split_size: list[float]) -> pd.DataFrame:\n",
        "    n_all = len(df_data_list)\n",
        "    counts = [int(n_all * size) for size in split_size]\n",
        "    counts[-1] = n_all - sum(counts[:-1])\n",
        "    dirname = np.array(split_dir_names)\n",
        "    dirname = np.repeat(dirname, counts)\n",
        "\n",
        "    np.random.seed(SEED)\n",
        "    np.random.shuffle(dirname)\n",
        "\n",
        "    save_path = AUDIOFOLDER_PATH + '/' + dirname + '/'\n",
        "    save_path = save_path + np.array([f'{i:03d}.wav' for i in range(n_all)])\n",
        "    df_data_list['save_path'] = save_path\n",
        "    return df_data_list"
      ],
      "metadata": {
        "id": "5QauAxxTRMJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aYvCT5YyUhAg"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import json\n",
        "import random\n",
        "import shutil\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def create_audiofolder(json_path, audiofolder_path,\n",
        "                       train_size, valid_size, test_size,\n",
        "                       apply_augment=False, # 音声データにノイズを付与するデータ拡張を行うかどうか\n",
        "                       add_normal=False, # 通常の声のデータをデータセットに含めるか\n",
        "                       json_path_normal=None,\n",
        "                       ):\n",
        "    # json読み込み\n",
        "    with open(json_path) as f:\n",
        "        json_data = json.load(f)\n",
        "    df_data_list = reshape_data(json_data)\n",
        "\n",
        "    # ランダムにtrain, validation, testに分ける\n",
        "    df_data_list = add_save_path(\n",
        "                df_data_list,\n",
        "                ['train', 'validation', 'test'],\n",
        "                [train_size, valid_size, test_size],\n",
        "    )\n",
        "\n",
        "    # 通常の声のデータを追加\n",
        "    if add_normal:\n",
        "        with open(json_path_normal) as f:\n",
        "            json_path_normal = json.load(f)\n",
        "        df_data_list_normal = reshape_data(json_path_normal)\n",
        "        df_data_list_normal = add_save_path(df_data_list_normal,\n",
        "                                            ['normal'], [1.0])\n",
        "        df_data_list = pd.concat([df_data_list, df_data_list_normal], ignore_index=True)\n",
        "\n",
        "    # データ拡張の定義\n",
        "    # if apply_augment:\n",
        "    #     augment = Compose([\n",
        "    #         # ガウスノイズを追加（音量の5%〜15%程度のノイズ）\n",
        "    #         AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=0.5),\n",
        "    #         # 速度を0.8倍〜1.2倍の間でランダムに変える\n",
        "    #         TimeStretch(min_rate=0.8, max_rate=1.2, p=0.5),\n",
        "    #         # ピッチ（声の高さ）を上下に2セミトーン変える\n",
        "    #         PitchShift(min_semitones=-2, max_semitones=2, p=0.5),\n",
        "    #     ])\n",
        "    # else:\n",
        "    #     augment = None\n",
        "\n",
        "    # audiofolderをリセット（消去）\n",
        "    if Path(audiofolder_path).exists():\n",
        "        shutil.rmtree(audiofolder_path)\n",
        "\n",
        "    for record in tqdm(df_data_list.itertuples()):\n",
        "        # 切り取り秒数\n",
        "        start = record.start\n",
        "        end = record.end\n",
        "        duration = end - start\n",
        "\n",
        "        # 保存先フォルダを作成\n",
        "        # 音声データを読み込み（兼切り取り、サンプリングレート変換、モノラル化）\n",
        "        wav_path = record.wav_path\n",
        "        data, sr = librosa.load(wav_path,\n",
        "                                offset=start,\n",
        "                                duration=duration,\n",
        "                                sr=16000,\n",
        "                                mono=True)\n",
        "\n",
        "        # データ拡張\n",
        "        # if augment is not None:\n",
        "        #     data = augment(samples=data.astype(np.float32), sample_rate=16000)\n",
        "\n",
        "        # 保存先フォルダを作成して保存\n",
        "        save_path = Path(record.save_path)\n",
        "        save_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "        sf.write(save_path, data, sr)\n",
        "\n",
        "        # metadata.csvに追加\n",
        "        csv_path = save_path.parent / 'metadata.csv'\n",
        "        new_file = not csv_path.exists()\n",
        "        with open(csv_path, 'a') as f:\n",
        "            writer = csv.DictWriter(f, fieldnames=['file_name', 'sentence'])\n",
        "            sentence = record.sentence.strip()\n",
        "            row = {'file_name': save_path.name, 'sentence': sentence}\n",
        "\n",
        "            if new_file:\n",
        "                writer.writeheader()\n",
        "                writer.writerow(row)\n",
        "            else:\n",
        "                writer.writerow(row)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#############################\n",
        "# メイン処理（audiofolder） #\n",
        "#############################\n",
        "create_audiofolder(\n",
        "    json_path=JSON_PATH,\n",
        "    audiofolder_path=AUDIOFOLDER_PATH,\n",
        "    train_size=0.8,\n",
        "    valid_size=0.1,\n",
        "    test_size=0.1,\n",
        "    apply_augment=APPLY_AUGMENT,\n",
        "    add_normal=ADD_NORMAL,\n",
        "    json_path_normal=JSON_PATH_NORMAL,\n",
        ")"
      ],
      "metadata": {
        "id": "Qf_OgR1l6RoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Audio, display\n",
        "from datasets import load_dataset\n",
        "\n",
        "def play_data(type, idx):\n",
        "    data_files = {p.name: str(p / '*') for p in Path(AUDIOFOLDER_PATH).iterdir()}\n",
        "    dataset = load_dataset('audiofolder', data_files=data_files);\n",
        "    record = dataset[type][idx]\n",
        "\n",
        "    display(Audio(data=record['audio']['array'], rate=record['audio']['sampling_rate']))\n",
        "    print(record['sentence'])\n",
        "\n",
        "play_data('normal', 1)"
      ],
      "metadata": {
        "id": "PkiZyZgWbGBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nAEeLB_qjIR3"
      },
      "outputs": [],
      "source": [
        "from transformers import WhisperProcessor\n",
        "\n",
        "processor = WhisperProcessor.from_pretrained(BASE_MODEL,\n",
        "                                             language='Japanese',\n",
        "                                             task='transcribe');\n",
        "\n",
        "def create_features_and_labels(record):\n",
        "    '''特徴量抽出と教師ラベルのトークン化(map用)\n",
        "    '''\n",
        "    # load and resample audio data from 48 to 16kHz\n",
        "    audio = record['audio']\n",
        "\n",
        "    # compute log-Mel input features from input audio array\n",
        "    record['input_features'] = processor.feature_extractor(audio['array']\n",
        "        , sampling_rate=audio['sampling_rate']).input_features[0]\n",
        "\n",
        "    # encode target text to label ids\n",
        "    record['labels'] = processor.tokenizer(record['sentence']).input_ids\n",
        "    return record"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "def create_preprocessed_data(audiofolder_path, preprocessed_data_path):\n",
        "    # audiofolder読み込み\n",
        "    data_files = {p.name: str(p / '*') for p in Path(audiofolder_path).iterdir()}\n",
        "    dataset = load_dataset('audiofolder', data_files=data_files);\n",
        "\n",
        "    # 特徴量抽出とトークン化\n",
        "    dataset = dataset.map(create_features_and_labels,\n",
        "                          remove_columns=dataset.column_names['train'],\n",
        "                          num_proc=NUM_PROC)\n",
        "\n",
        "    # preprocessed_dataをリセット（消去）\n",
        "    preprocessed_data_path = Path(preprocessed_data_path)\n",
        "    if preprocessed_data_path.exists():\n",
        "        shutil.rmtree(preprocessed_data_path)\n",
        "\n",
        "    # 保存\n",
        "    dataset.save_to_disk(preprocessed_data_path)"
      ],
      "metadata": {
        "id": "ZoV-pt-veusc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###################################\n",
        "# メイン処理（preprocessed_data） #\n",
        "###################################\n",
        "create_preprocessed_data(\n",
        "    audiofolder_path=AUDIOFOLDER_PATH,\n",
        "    preprocessed_data_path=PREPROCESSED_DATA_PATH,\n",
        ")"
      ],
      "metadata": {
        "id": "gtnl39aIf1RL"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMLRFtu8ldTmcqWyByLJ2JA",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}