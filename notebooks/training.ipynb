{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNIIVgY+fgM85cXprFSohx6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/y-chiba1008/talk-support-asr/blob/main/notebooks/training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip -q install evaluate ginza ja-ginza jiwer audiomentations"
      ],
      "metadata": {
        "id": "FWIamc5PrPvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1-siXDznUJg"
      },
      "outputs": [],
      "source": [
        "# ドライブのdataフォルダをマウント\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "## Google Driveをマウント\n",
        "drive.mount('/drive')\n",
        "\n",
        "## シンボリックリンクの作成\n",
        "links = [\n",
        "    {'from': '/drive/Othercomputers/マイ コンピュータ/data', 'to': '/content/data'},\n",
        "    {'from': '/drive/Othercomputers/マイ コンピュータ/model', 'to': '/content/model'},\n",
        "];\n",
        "\n",
        "for link in links:\n",
        "    drive_folder_path = link['from']\n",
        "    colab_link_path = link['to']\n",
        "\n",
        "    ### リンク先が既に存在する場合は削除\n",
        "    if os.path.isdir(colab_link_path):\n",
        "        print(f'{colab_link_path}がすでに存在する為、一度削除します')\n",
        "        !rm -rf \"$colab_link_path\"\n",
        "\n",
        "    ### シンボリックリンクを作成\n",
        "    !ln -s \"$drive_folder_path\" \"$colab_link_path\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 定数\n",
        "PREPROCESSED_DATA_PATH = 'data/02_all/preprocessed_data'\n",
        "BASE_MODEL = 'openai/whisper-small'\n",
        "SEED = 42\n",
        "DROPOUT_RATE = 0.1\n",
        "LORA_ENABLE = True\n",
        "LORA_R = 32"
      ],
      "metadata": {
        "id": "HE3NZ57poV13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## データコレータ"
      ],
      "metadata": {
        "id": "Aa-126sXqadA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dataclasses import dataclass\n",
        "import torch\n",
        "from transformers import WhisperProcessor\n",
        "\n",
        "@dataclass\n",
        "class DataCollatorSpeechSeq2SeqWithPadding:\n",
        "    '''データコレータ\n",
        "    '''\n",
        "    processor: WhisperProcessor\n",
        "\n",
        "    def __call__(self, features: list[dict[str, list[int] | torch.Tensor]]) -> dict[str, torch.Tensor]:\n",
        "\n",
        "        # 音響特徴量側をまとめる処理\n",
        "        # (一応バッチ単位でパディングしているが、すべて30秒分であるはず)\n",
        "        input_features \\\n",
        "            = [{'input_features': feature['input_features']} for feature in features]\n",
        "        batch = self.processor.feature_extractor.pad(input_features, return_tensors='pt')\n",
        "\n",
        "        # トークン化された系列をバッチ単位でパディング\n",
        "        label_features = [{'input_ids': feature['labels']} for feature in features]\n",
        "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors='pt')\n",
        "\n",
        "        # attention_maskが0の部分は、トークンを-100に置き換えてロス計算時に無視させる\n",
        "        # -100を無視するのは、PyTorchの仕様\n",
        "        labels \\\n",
        "            = labels_batch['input_ids'].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
        "\n",
        "        # BOSトークンがある場合は削除\n",
        "        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n",
        "            labels = labels[:, 1:]\n",
        "\n",
        "        # 整形したlabelsをバッチにまとめる\n",
        "        batch['labels'] = labels\n",
        "\n",
        "        return batch\n"
      ],
      "metadata": {
        "id": "qbpFxf5HpFad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 評価関数"
      ],
      "metadata": {
        "id": "FL2qKoOlqhk7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dataclasses import dataclass\n",
        "import evaluate\n",
        "from evaluate import EvaluationModule\n",
        "import ginza\n",
        "import spacy\n",
        "from spacy import Language\n",
        "from transformers import WhisperProcessor\n",
        "\n",
        "@dataclass\n",
        "class ComputeMetrics:\n",
        "    \"\"\"メトリクス計算処理\"\"\"\n",
        "    processor: WhisperProcessor\n",
        "    metric: EvaluationModule\n",
        "    nlp: Language\n",
        "\n",
        "    def __init__(self, processor: WhisperProcessor) -> None:\n",
        "        # Processor\n",
        "        self.processor = processor\n",
        "\n",
        "        # metric(wer)\n",
        "        self.metric = evaluate.load('wer')\n",
        "\n",
        "        # nlp\n",
        "        nlp = spacy.load('ja_ginza')\n",
        "        ginza.set_split_mode(nlp, 'C')\n",
        "        self.nlp = nlp\n",
        "\n",
        "    def __call__(self, pred):\n",
        "        \"\"\"metricsを計算する\"\"\"\n",
        "        pred_ids = pred.predictions\n",
        "        label_ids = pred.label_ids\n",
        "\n",
        "        # '-100'をパディングトークンに変換\n",
        "        label_ids[label_ids == -100] = self.processor.tokenizer.pad_token_id\n",
        "\n",
        "        # トークン列→文字列に変換\n",
        "        pred_strs = self.processor.tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
        "        label_strs = self.processor.tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
        "\n",
        "        wer = self.compute_wer(pred_strs, label_strs)\n",
        "\n",
        "        return {'wer': wer}\n",
        "\n",
        "    def insert_spaces(self, sentences: list[str]) -> list[str]:\n",
        "        '''文字列を単語ごとに分解して、スペース区切りにする'''\n",
        "        spaced_sentences = []\n",
        "        for sentence in sentences:\n",
        "            doc = self.nlp(sentence)\n",
        "            words = [token.text for token in doc]\n",
        "            spaced_sentence = ' '.join(words)\n",
        "            spaced_sentences.append(spaced_sentence)\n",
        "\n",
        "        return spaced_sentences\n",
        "\n",
        "    def compute_wer(self, pred_strs: list[str], label_strs: list[str]):\n",
        "        '''WERを計算する'''\n",
        "        # 予測と正解ラベルの単語間にスペースを挿入\n",
        "        preds_spaced = self.insert_spaces(pred_strs)\n",
        "        labels_spaced = self.insert_spaces(label_strs)\n",
        "\n",
        "        # WERを計算\n",
        "        wer = 100 * self.metric.compute(predictions=preds_spaced, references=labels_spaced)\n",
        "        return wer"
      ],
      "metadata": {
        "id": "cTE2f3q-qkh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GenerationConfig\n",
        "from transformers import WhisperForConditionalGeneration\n",
        "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
        "\n",
        "def load_model(base_model, lora=False):\n",
        "    \"\"\"モデルのロード\"\"\"\n",
        "    model = WhisperForConditionalGeneration.from_pretrained(base_model)\n",
        "\n",
        "    model.config.use_cache = False\n",
        "\n",
        "    # 各種ドロップアウトパラメータを更新\n",
        "    model.config.dropout = DROPOUT_RATE            # 全結合層などの基本ドロップアウト\n",
        "    model.config.attention_dropout = DROPOUT_RATE  # アテンション層のドロップアウト\n",
        "    model.config.activation_dropout = DROPOUT_RATE # 活性化関数後のドロップアウト\n",
        "\n",
        "    # SpecAugment系設定（データの一部をマスキングして過学習を防ぐ）\n",
        "    model.config.apply_spec_augment = True\n",
        "    model.config.mask_time_prob = 0.05       # 時間方向にマスクをかける確率\n",
        "    model.config.mask_time_length = 10      # 時間方向のマスクの最大幅\n",
        "    model.config.mask_feature_prob = 0.05   # 周波数方向にマスクをかける確率\n",
        "    model.config.mask_feature_length = 10   # 周波数方向のマスクの最大幅\n",
        "\n",
        "    # LoRA適用\n",
        "    if lora:\n",
        "        model = prepare_model_for_kbit_training(model)\n",
        "        lora_config = LoraConfig(\n",
        "            r=LORA_R,                           # ランク数。大きいほど表現力が増すが過学習のリスクも増える（8, 16, 32が一般的）\n",
        "            lora_alpha=LORA_R * 2,              # スケーリング係数。通常は r の2倍程度に設定\n",
        "            target_modules=['q_proj', 'v_proj'], # Whisperのどの層に適用するか（Attention層が一般的）\n",
        "            lora_dropout=0.1,                   # LoRA層内のドロップアウト\n",
        "            bias='none',\n",
        "        )\n",
        "        model = get_peft_model(model, lora_config)\n",
        "\n",
        "    # その他の設定\n",
        "    model.generation_config = GenerationConfig.from_pretrained(base_model)\n",
        "    model.generation_config.language = 'japanese'\n",
        "    model.generation_config.task = 'transcribe'\n",
        "    model.generation_config.forced_decoder_ids = None # 念のためクリア\n",
        "    model.generation_config.use_cache = False\n",
        "    return model"
      ],
      "metadata": {
        "id": "QSQj4jAToJGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Seq2SeqTrainingArguments\n",
        "from transformers import Seq2SeqTrainer\n",
        "from transformers import EarlyStoppingCallback\n",
        "from transformers import WhisperProcessor\n",
        "\n",
        "def get_trainer(model, dataset):\n",
        "    training_args = Seq2SeqTrainingArguments(\n",
        "        output_dir='./whisper-small-ja', # 出力ディレクトリ\n",
        "        seed=SEED,\n",
        "        data_seed=SEED,\n",
        "\n",
        "        learning_rate=1e-5, # 学習率\n",
        "        # metric_for_best_model='wer',\n",
        "        metric_for_best_model='eval_loss',\n",
        "\n",
        "        # max_steps=10, # 学習ステップ数\n",
        "        # warmup_steps=2,\n",
        "        # eval_steps=2,\n",
        "        # logging_steps=2,\n",
        "        # save_steps=2,\n",
        "\n",
        "        max_steps=4000, # 学習ステップ数\n",
        "        warmup_steps=500,\n",
        "        eval_steps=50,\n",
        "        logging_steps=50,\n",
        "\n",
        "        # チェックポイント\n",
        "        save_total_limit=2,\n",
        "        save_steps=50,\n",
        "\n",
        "        # 過学習対策\n",
        "        weight_decay=0.01,\n",
        "        lr_scheduler_type='cosine',\n",
        "        # lr_scheduler_type='linear',\n",
        "\n",
        "        # max_steps=4000, # Hugging Faceブログではこちら\n",
        "        # warmup_steps=500, # Hugging Faceブログではこちら\n",
        "\n",
        "        per_device_train_batch_size=5,\n",
        "        per_device_eval_batch_size=5,\n",
        "        group_by_length=True,\n",
        "\n",
        "        gradient_accumulation_steps=1,\n",
        "        # gradient_checkpointing=True,\n",
        "        fp16=True,\n",
        "        # fp16=False, # lossの計算の検証のため\n",
        "        predict_with_generate=True,\n",
        "        generation_max_length=225,\n",
        "        load_best_model_at_end=True,\n",
        "        greater_is_better=False,\n",
        "        report_to=['none'],\n",
        "        eval_strategy='steps', # 評価を行うタイミング (steps, epochなど)\n",
        "        push_to_hub=False,\n",
        "        gradient_checkpointing=False,\n",
        "    )\n",
        "\n",
        "    # 早期終了\n",
        "    early_stopping = EarlyStoppingCallback(\n",
        "        early_stopping_patience=3,        # 3回(計1500ステップ)改善がなければ終了\n",
        "        early_stopping_threshold=0.001    # どの程度の改善を「進歩」とみなすかの閾値（任意）\n",
        "    )\n",
        "\n",
        "    # processor\n",
        "    processor = WhisperProcessor.from_pretrained(BASE_MODEL,\n",
        "                                             language='Japanese',\n",
        "                                             task='transcribe');\n",
        "\n",
        "    # データコレータ\n",
        "    data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor)\n",
        "\n",
        "    # メトリクス計算クラス\n",
        "    compute_metrics = ComputeMetrics(processor)\n",
        "\n",
        "    trainer = Seq2SeqTrainer(\n",
        "        args=training_args,\n",
        "        model=model,\n",
        "        train_dataset=dataset['train'],\n",
        "        eval_dataset=dataset['validation'],\n",
        "        data_collator=data_collator,\n",
        "        compute_metrics=compute_metrics,\n",
        "        processing_class=processor.feature_extractor,\n",
        "        callbacks=[early_stopping],\n",
        "    )\n",
        "\n",
        "    return trainer"
      ],
      "metadata": {
        "id": "vtEYjC8RTQ2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from datasets import load_from_disk\n",
        "\n",
        "# GPUで実行する\n",
        "assert torch.cuda.is_available()\n",
        "\n",
        "model = load_model(BASE_MODEL, lora=LORA_ENABLE)\n",
        "dataset = load_from_disk(PREPROCESSED_DATA_PATH)\n",
        "trainer = get_trainer(model, dataset)\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "L5tuwhSDXaCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_predict(predict_result, processor):\n",
        "    pred_sentences = processor.tokenizer.batch_decode(predict_result.predictions, skip_special_tokens=True)\n",
        "    label_sentences = processor.tokenizer.batch_decode(predict_result.label_ids, skip_special_tokens=True)\n",
        "\n",
        "    for pre, lab in zip(pred_sentences, label_sentences):\n",
        "        lab = lab.splitlines()[0]\n",
        "        pre = pre.splitlines()[0]\n",
        "        print(f'ラベル  : {lab}')\n",
        "        print(f'推論結果: {pre}')\n",
        "\n",
        "    print(f'\\n')\n",
        "    print(f'WER: {predict_result.metrics['test_wer']}')"
      ],
      "metadata": {
        "id": "pmaep4SxAUmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_result = trainer.predict(dataset['test'],\n",
        "                                language='ja',\n",
        "                                task='transcribe')\n",
        "show_predict(predict_result, trainer.data_collator.processor)"
      ],
      "metadata": {
        "id": "FEzPeuqtAIGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "def save_model(trainer, output_dir):\n",
        "    output_dir = Path(output_dir)\n",
        "    assert not output_dir.exists(), f'すでに存在するディレクトリです[{output_dir}]\\nデータの上書きを防ぐため、保存先は存在しないディレクトリを指定してください'\n",
        "\n",
        "    # モデル本体の保存\n",
        "    trainer.save_model(output_dir)\n",
        "\n",
        "    # プロセッサ（Feature ExtractorとTokenizer）の保存\n",
        "    trainer.data_collator.processor.save_pretrained(output_dir)\n",
        "\n",
        "# 保存先のパス\n",
        "output_dir = './data/model/20260126_01'\n",
        "\n",
        "# save_model(trainer, output_dir)"
      ],
      "metadata": {
        "id": "5c_sfnm5EMCc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}